{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pip install langchain-anthropic langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Collection\n",
    "\n",
    "You can think of this as a collection of facts or \"semantic\" memory. \n",
    "\n",
    "These are things that the LLM extracts over time from the user's journal. \n",
    "\n",
    "Let's build on what we did in the previous lessons.\n",
    "\n",
    "First, we define a general schema for any memory.\n",
    "\n",
    "The schema has a `memory_type` and a `memory_content`.\n",
    "\n",
    "![](./img/memory_course_semantic_collection.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Schema for structured output\n",
    "class Memory(BaseModel):\n",
    "    memory_type: str = Field(None, description=\"Type of memory to extract.\")\n",
    "    memory_content: str = Field(None, description=\"Specific content of the memory.\")\n",
    "\n",
    "class Memories(BaseModel):\n",
    "    memories: List[Memory] = Field(None, description=\"List of memories to extract.\")\n",
    "\n",
    "# Define and augment LLM with structured output\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "structured_llm = llm.with_structured_output(Memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load our instructions for memory extraction and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import src.memory_course.prompts\n",
    "import src.memory_course.examples\n",
    "import src.memory_course.utils\n",
    "\n",
    "# Reload the module in case any changes were made\n",
    "import importlib\n",
    "importlib.reload(src.memory_course.prompts)\n",
    "importlib.reload(src.memory_course.examples)\n",
    "importlib.reload(src.memory_course.utils)\n",
    "\n",
    "# Then import the instructions and examples\n",
    "from src.memory_course.utils import format_few_shot_examples\n",
    "from src.memory_course.examples import example_input, example_output\n",
    "from src.memory_course.prompts import memory_collection_extraction_instructions, memory_search_instructions, collection_extraction_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save instructions to the store\n",
    "from datetime import datetime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "namespace = (\"journal\",\"instructions\")\n",
    "key = \"instructions_extraction\"\n",
    "in_memory_store.put(namespace, key, {\"instructions\": memory_collection_extraction_instructions})\n",
    "\n",
    "namespace = (\"journal\",\"examples\")\n",
    "key = f\"example_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "in_memory_store.put(namespace, key, {\"input\": example_input, \"output\": example_output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we define a function to extract memories from a journal entry that uses both instruction and few shot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def extract_memories(journal_entry: str) -> Memories:\n",
    "    \"\"\"Extract memories from a journal entry.\n",
    "    \n",
    "    This function analyzes a journal entry and extracts memories\n",
    "    \n",
    "    Args:\n",
    "        journal_entry (str): The text of the journal entry to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Memories (list): A structured list of Memory objects\"\"\"\n",
    "\n",
    "    # Get the instructions from the store\n",
    "    namespace = (\"journal\",\"instructions\")\n",
    "    key = \"instructions_extraction\"\n",
    "    instructions = in_memory_store.get(namespace, key)\n",
    "\n",
    "    # Get the examples from the store\n",
    "    few_shot_examples = in_memory_store.search((\"journal\", \"examples\"))\n",
    "    few_shot_examples_formatted = format_few_shot_examples(few_shot_examples)\n",
    "\n",
    "    # Format the instructions\n",
    "    memory_extraction_instructions_formatted = collection_extraction_input.format(\n",
    "        procedural_memory_instructions=instructions.value['instructions'],\n",
    "        few_shot_examples_formatted=few_shot_examples_formatted\n",
    "    )\n",
    "\n",
    "    # Extract memories\n",
    "    memories = structured_llm.invoke([SystemMessage(content=memory_extraction_instructions_formatted),\n",
    "                                      HumanMessage(content=f\"Extract memory from <context> {journal_entry} </context>\")])\n",
    "    \n",
    "    return memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extracted Memory ===\n",
      "\n",
      "SENTIMENT:\n",
      "- Highly positive and confident mood despite workload. Enthusiasm about technical progress and sprint goals. Key phrases: 'productive', 'working better than expected', 'feeling pretty confident', 'positive results'\n",
      "\n",
      "=== Extracted Memory ===\n",
      "\n",
      "TODO:\n",
      "- Set up meeting with DevOps team about deployment strategy\n",
      "\n",
      "=== Extracted Memory ===\n",
      "\n",
      "TODO:\n",
      "- Fix unit tests for the payment module (Deadline: Friday)\n",
      "\n",
      "=== Extracted Memory ===\n",
      "\n",
      "TODO:\n",
      "- Order new laptop charger\n",
      "\n",
      "=== Extracted Memory ===\n",
      "\n",
      "TODO:\n",
      "- Update documentation for API changes\n",
      "\n",
      "=== Extracted Memory ===\n",
      "\n",
      "IDEA:\n",
      "- Implement automatic test generation using LLMs to reduce manual test writing time. Requirements: Evaluate cost and accuracy feasibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test extraction of memories\n",
    "journal_entry = \"\"\"\n",
    "Really productive coding session this morning! The new refactoring approach is working better than expected, though I hit a few snags with the database migrations.\n",
    "\n",
    "Important tasks for this week:\n",
    "- Set up meeting with DevOps team about deployment strategy\n",
    "- Fix unit tests for the payment module by Friday\n",
    "- Order new laptop charger\n",
    "- Update documentation for API changes\n",
    "\n",
    "During the team standup, had a fascinating idea about improving our testing workflow. What if we implemented automatic test generation using LLMs? Could save hours of manual test writing. Would need to evaluate cost and accuracy first.\n",
    "\n",
    "Even though there's a lot on my plate, feeling pretty confident about the sprint goals. The recent architecture changes are already showing positive results.\"\"\"\n",
    "\n",
    "# Run extraction\n",
    "memories = extract_memories(journal_entry)\n",
    "\n",
    "# Review\n",
    "for memory in memories.memories:\n",
    "    print(\"=== Extracted Memory ===\")\n",
    "    print(f\"\\n{memory.memory_type.upper()}:\")\n",
    "    print(f\"- {memory.memory_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With memories extracted from the journal entry, we can store them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def store_memory_collection(memories):\n",
    "    \"\"\"Store a collection of extracted memories in the memory store.\n",
    "        \n",
    "    Args:\n",
    "        memories (List[Memory]): List of Memory objects, where each Memory has:\n",
    "            - memory_type: str, one of [\"SENTIMENT\", \"TODO\", \"IDEA\"]\n",
    "            - memory_content: str, the extracted content\n",
    "            - timestamp: str, ISO format timestamp\n",
    "            \n",
    "    Returns:\n",
    "        None: Memories are stored in the in-memory store as a side effect\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through each memory and store in appropriate collection\n",
    "    for memory in memories.memories:\n",
    "\n",
    "        # Generate a unique UUID for each memory\n",
    "        memory_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Create namespace tuple with the specific collection type (memory_type)\n",
    "        namespace = (\"journal\", \"memory\", \"collection\", memory.memory_type.lower())\n",
    "        \n",
    "        # Create the key using the UUID\n",
    "        key = f\"memory_{memory_id}\"\n",
    "        \n",
    "        # Create the value object according to the schema\n",
    "        value = {\n",
    "            \"memory\": memory.memory_content,  #\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "        \n",
    "        # Store in the database\n",
    "        in_memory_store.put(namespace, key, value)\n",
    "\n",
    "store_memory_collection(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['journal', 'semantic', 'collection', 'todo'], key='memory_5951f267-9b73-4198-9b17-c017ffc71808', value={'memory': 'Set up meeting with DevOps team about deployment strategy', 'timestamp': '2025-02-03T13:48:57.451657'}, created_at='2025-02-03T21:48:57.451663+00:00', updated_at='2025-02-03T21:48:57.451664+00:00', score=None),\n",
       " Item(namespace=['journal', 'semantic', 'collection', 'todo'], key='memory_9337cc2e-d7b3-4351-90f0-902acd7dffb1', value={'memory': 'Fix unit tests for the payment module (Deadline: Friday)', 'timestamp': '2025-02-03T13:48:57.451675'}, created_at='2025-02-03T21:48:57.451680+00:00', updated_at='2025-02-03T21:48:57.451681+00:00', score=None),\n",
       " Item(namespace=['journal', 'semantic', 'collection', 'todo'], key='memory_0fb65069-c8ea-4b22-b06e-7c83e15ca681', value={'memory': 'Order new laptop charger', 'timestamp': '2025-02-03T13:48:57.451695'}, created_at='2025-02-03T21:48:57.451700+00:00', updated_at='2025-02-03T21:48:57.451700+00:00', score=None),\n",
       " Item(namespace=['journal', 'semantic', 'collection', 'todo'], key='memory_8465d5cf-945d-4b9a-9810-4bdfe75a56ce', value={'memory': 'Update documentation for API changes', 'timestamp': '2025-02-03T13:48:57.451707'}, created_at='2025-02-03T21:48:57.451711+00:00', updated_at='2025-02-03T21:48:57.451712+00:00', score=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search\n",
    "namespace = (\"journal\", \"memory\", \"collection\", \"todo\")\n",
    "in_memory_store.search(namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we also want the ability to search for memories across all collections in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for structured output\n",
    "class MemorySearch(BaseModel):\n",
    "    collection: str=Field(None, description=\"Name of the memory collection to search\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'todo'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_collection_to_search(user_input):\n",
    "    \"\"\"Get the collection to search based on user input.\"\"\"\n",
    "\n",
    "    # Get the last element of each namespace tuple which represents the collection type\n",
    "    namespace = (\"journal\", \"memory\", \"collection\")\n",
    "    all_memories = in_memory_store.search(namespace)\n",
    "    unique_collections = sorted({item.namespace[-1] for item in all_memories})\n",
    "\n",
    "    # Format the prompt\n",
    "    structured_llm = llm.with_structured_output(MemorySearch)\n",
    "    search_instructions_formatted = memory_search_instructions.format(available_collections=unique_collections,  \n",
    "                                                               memory_classification_prompt=memory_collection_extraction_instructions)\n",
    "    # Get the collection to search\n",
    "    collection = structured_llm.invoke([SystemMessage(content=search_instructions_formatted), HumanMessage(content=f\"<User Input>{user_input}</User Input>\")])\n",
    "    return collection.collection\n",
    "\n",
    "get_collection_to_search(\"What are my ToDos for the day?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily search for memories in the given collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract semantic collection\n",
    "def search_and_format_semantic_collection(collection_type):\n",
    "    \"\"\" Format episodic memories for few shot examples\"\"\"\n",
    "\n",
    "    # Search the collection\n",
    "    collection = in_memory_store.search((\"journal\", \"semantic\", \"collection\", collection_type))\n",
    "\n",
    "    # Sort items by creation timestamp\n",
    "    sorted_items = sorted(collection, key=lambda x: x.created_at)\n",
    "    \n",
    "    # Extract memory contents\n",
    "    memories = []\n",
    "    for item in sorted_items:\n",
    "        if isinstance(item.value.get('memory'), Memory):\n",
    "            memories.append(item.value['memory'].memory_content)\n",
    "        else:\n",
    "            memories.append(item.value.get('memory'))\n",
    "    \n",
    "    output = [\n",
    "        f\"Collection Type: {collection_type.upper()}\",\n",
    "        \"Sorted by: Creation Time (Oldest to Newest)\",\n",
    "        \"\\nItems:\",\n",
    "        *[f\"• {memory}\" for memory in memories]\n",
    "    ]\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "collection_type = get_collection_to_search(\"What are my ToDos for the day?\")\n",
    "collection_formatted = search_and_format_semantic_collection(collection_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collection Type: TODO\\nSorted by: Creation Time (Oldest to Newest)\\n\\nItems:\\n• Set up meeting with DevOps team about deployment strategy\\n• Fix unit tests for the payment module (Deadline: Friday)\\n• Order new laptop charger\\n• Update documentation for API changes'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can:\n",
    "\n",
    "1. Extract memories from a journal entry given a set of instructions (system message)\n",
    "2. Update those instructions based upon user feedback directly \n",
    "3. Add few shot examples to improve the quality of the extraction\n",
    "4. Update those few shot examples based upon user feedback directly \n",
    "5. Save a collection of extracted memories to the store\n",
    "6. Search for memories in a given collection in natural language\n",
    "\n",
    "This is a simple example of using and editing both \"procedural memory\" (system prompt/instructions) and \"episodic memory\" (few shot examples). \n",
    "\n",
    "In addition, we save \"semantic memories\" (facts) about the users in specific collections.\n",
    "\n",
    "And we can search for memories in a given collection in natural language. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memory-course-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
